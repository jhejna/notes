{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home \u00b6 This site serves as a collection of notes I take on various subjects. Have fun exploring! About me \u00b6 If you're interested in know more about me or the projects I have done in the past, checkout my portfolio website . I currently work on reinforcement learning research at UC Berkeley. Content \u00b6 Introductory Machine Learning Notes Advanced Python Notes","title":"Home"},{"location":"#home","text":"This site serves as a collection of notes I take on various subjects. Have fun exploring!","title":"Home"},{"location":"#about-me","text":"If you're interested in know more about me or the projects I have done in the past, checkout my portfolio website . I currently work on reinforcement learning research at UC Berkeley.","title":"About me"},{"location":"#content","text":"Introductory Machine Learning Notes Advanced Python Notes","title":"Content"},{"location":"machine%20learning/","text":"0. Introduction \u00b6","title":"0. Introduction"},{"location":"machine%20learning/#0-introduction","text":"","title":"0. Introduction"},{"location":"machine%20learning/1data/","text":"1. Distributions, Data, and Probability \u00b6 Machine learning begis with data -- it's what we use to make our decisions and develop reasoning about the world. In the field of machine learning, we make the strong assumption that all of our data is derived from a probability distribution . It's OK if you don't know what that means yet. This section will be about data and how we interpret it using a probablistic framework. Additionally, it will provide a brief background on probability necesary for topics down the line. Probability \u00b6 Probability is mathematical framework used to understand the randomness. Our world is random, and thus so is our data. Here are a few examples of randomness present in data: Ordering of the deck in card games The actions of other players or humans, including mistakes in labeling data. Quantum level interactions of light that change images. noise in sensors By applying a probablistic framework to our data, we hope to make sense of all these sources of randomness. Let's begin with a simple example, we'll use throughout this note: Ex: Tossing Coins You have a coin, but aren't sure if it is fair or not. We define the coin to be fair if it truly lands on heads 50% of the time. How can we figure out if this is true? By collecting an analyzing data. Every time we flip the coin, there are two things that can happen. The coin can land on heads or it can land on tails. This means our random experiment of flipping the coin has two probablistic outcomes \\omega \\omega , either \\omega = H \\omega = H for heads or \\omega = T \\omega = T for tails. In probability, we denote each possible result of a random trial by an outcome, \\omega \\omega and the set of all possible outcomes as \\Omega \\Omega . In our coin flipping example, \\Omega = \\{H,T\\} \\Omega = \\{H,T\\} . If the coin is fair, we believe the probability of getting heads, or P(H) = 0.5 P(H) = 0.5 or 50%. Using this intuition, we can define the basics of a probability space. Definition : A probability space (\\Omega, P) (\\Omega, P) is a set of collectively exhaustive outcomes \\Omega \\Omega and a function P: \\Omega \\rightarrow \\mathbb{R} P: \\Omega \\rightarrow \\mathbb{R} such that the following are true: P(\\omega) \\geq 0, \\forall \\omega \\in \\Omega P(\\omega) \\geq 0, \\forall \\omega \\in \\Omega or every outcome has some assigned likelihood. \\sum_{\\omega \\in \\Omega} P(\\omega) = 1 \\sum_{\\omega \\in \\Omega} P(\\omega) = 1 or the total probability has to sum to one. In our coin flipping example, we had two outcomes H, T H, T . However, this notion of probability generalizes to more scenarios. Let's say we can collect three data points to figure out if the coin is fair or not. Our new outcomes are defined by the eight possible results, including HHH, TTT, HTH, THH, HHH, TTT, HTH, THH, etc. The probability of each of these outcomes is 0.5 \\times 0.5 \\times 0.5 = 0.125 0.5 \\times 0.5 \\times 0.5 = 0.125 as assuming the coin is fair, each flip has a 0.5 0.5 chance of landing on heads. The probability of any outcome happening is one -- after we flip the coin three times, one of the outcomes in our set must have occured. Random Variables \u00b6 When we're dealing with thousands of data points, dealing with probability spaces becomes rather cumbersome. Imagine that you want to flip the coin 10,000 times to determine whether or not it's fair. The outcome space contain 2^10000 2^10000 possible outcomes! We can define abstractions on top of our probability space that makes dealing with large amounts of data or randomness easier. To do so, we define a random variable that converts each outcome to a real value. Definition : A random variable is a function X: \\Omega \\rightarrow \\mathbb{R}^d X: \\Omega \\rightarrow \\mathbb{R}^d . When flipping a coin, we can assign X = 1 X = 1 when the result is heads, or X = 0 X = 0 when the result is tails. Rather than say \"heads\" or \"tails\" our data is just zeros and ones. What if we flip the coin 10 times? Well, we collect 10 data points X_1, X_2, ..., X_{10} X_1, X_2, ..., X_{10} . The total number of heads Z Z would be Z = \\sum_{i=1}^{10} X_i Z = \\sum_{i=1}^{10} X_i , which is just an integer between 0 and 10. That's great, but what about probabilities? They simply carry over from the sample space: P(H) = P(X=1) = 0.5 P(H) = P(X=1) = 0.5 . P(HHHHHHHHHH) = P(Y=10) = (0.5)^{10} P(HHHHHHHHHH) = P(Y=10) = (0.5)^{10} Distributions \u00b6 The possible values of a random variable together with the probabilities that it takes on each value defines the distribution of the random variable. This allows us to reason about the characteristics of a random variable. Definition : The distribution of a random variable X X is the set of all values the random variable can take on x \\in \\mathcal{X} x \\in \\mathcal{X} , and their probabilities P(X = x) P(X = x) . Formally, (x, P(X=x)) \\forall x \\in \\mathcal{X} (x, P(X=x)) \\forall x \\in \\mathcal{X} . So far, this has worked great for coin-flipping, as everything has been an integer value! But what if we have a continuous set of outcomes, where the data we collect can take on any value in the interval [0,1] [0,1] . Let's try to assign probabilities. Let's say that P(0.025) = 0.0000001 P(0.025) = 0.0000001 , however there are an infinite number of possible outcomes, as there are infinitely many values between zero and one. If each outcome has non-zero probability, the total probability will sum to over 1! If we only assign non-zero probabilities to some outcomes, we reduce back to the discrete case. Thus, each outcome must have zero probability, yet they all sum to 1. To reconcile this disparity, we argue about continuous probability using random variables and distributions. Definition The distribution of a continuous random variable X X is defined by a probability density function f_X : X \\rightarrow \\mathbb{R} f_X : X \\rightarrow \\mathbb{R} such that: P(a \\leq X \\leq b) = \\int_a^b f_X(x) dx P(a \\leq X \\leq b) = \\int_a^b f_X(x) dx \\int_{-\\infty}^{\\infty} f_X(x) dx = 1 \\int_{-\\infty}^{\\infty} f_X(x) dx = 1 Intuitively, this defintion makes sense. If every value between 0 and 1 is equally likely, the probability P(X \\leq 0.5) P(X \\leq 0.5) should be 0.5. If we define f_X to be uniform and equal to 1 over the interval [0,1] [0,1] this happens to be the case. Note that the values of the density function f_X(x) f_X(x) can be larger than one, and even infinite! Below are some examples of distributions: Expectation \u00b6 Variance \u00b6 Data in ML \u00b6 In machine learning, we create a dataset containing samples from the real world.","title":"1. Distributions, Data, and Probability"},{"location":"machine%20learning/1data/#1-distributions-data-and-probability","text":"Machine learning begis with data -- it's what we use to make our decisions and develop reasoning about the world. In the field of machine learning, we make the strong assumption that all of our data is derived from a probability distribution . It's OK if you don't know what that means yet. This section will be about data and how we interpret it using a probablistic framework. Additionally, it will provide a brief background on probability necesary for topics down the line.","title":"1. Distributions, Data, and Probability"},{"location":"machine%20learning/1data/#probability","text":"Probability is mathematical framework used to understand the randomness. Our world is random, and thus so is our data. Here are a few examples of randomness present in data: Ordering of the deck in card games The actions of other players or humans, including mistakes in labeling data. Quantum level interactions of light that change images. noise in sensors By applying a probablistic framework to our data, we hope to make sense of all these sources of randomness. Let's begin with a simple example, we'll use throughout this note: Ex: Tossing Coins You have a coin, but aren't sure if it is fair or not. We define the coin to be fair if it truly lands on heads 50% of the time. How can we figure out if this is true? By collecting an analyzing data. Every time we flip the coin, there are two things that can happen. The coin can land on heads or it can land on tails. This means our random experiment of flipping the coin has two probablistic outcomes \\omega \\omega , either \\omega = H \\omega = H for heads or \\omega = T \\omega = T for tails. In probability, we denote each possible result of a random trial by an outcome, \\omega \\omega and the set of all possible outcomes as \\Omega \\Omega . In our coin flipping example, \\Omega = \\{H,T\\} \\Omega = \\{H,T\\} . If the coin is fair, we believe the probability of getting heads, or P(H) = 0.5 P(H) = 0.5 or 50%. Using this intuition, we can define the basics of a probability space. Definition : A probability space (\\Omega, P) (\\Omega, P) is a set of collectively exhaustive outcomes \\Omega \\Omega and a function P: \\Omega \\rightarrow \\mathbb{R} P: \\Omega \\rightarrow \\mathbb{R} such that the following are true: P(\\omega) \\geq 0, \\forall \\omega \\in \\Omega P(\\omega) \\geq 0, \\forall \\omega \\in \\Omega or every outcome has some assigned likelihood. \\sum_{\\omega \\in \\Omega} P(\\omega) = 1 \\sum_{\\omega \\in \\Omega} P(\\omega) = 1 or the total probability has to sum to one. In our coin flipping example, we had two outcomes H, T H, T . However, this notion of probability generalizes to more scenarios. Let's say we can collect three data points to figure out if the coin is fair or not. Our new outcomes are defined by the eight possible results, including HHH, TTT, HTH, THH, HHH, TTT, HTH, THH, etc. The probability of each of these outcomes is 0.5 \\times 0.5 \\times 0.5 = 0.125 0.5 \\times 0.5 \\times 0.5 = 0.125 as assuming the coin is fair, each flip has a 0.5 0.5 chance of landing on heads. The probability of any outcome happening is one -- after we flip the coin three times, one of the outcomes in our set must have occured.","title":"Probability"},{"location":"machine%20learning/1data/#random-variables","text":"When we're dealing with thousands of data points, dealing with probability spaces becomes rather cumbersome. Imagine that you want to flip the coin 10,000 times to determine whether or not it's fair. The outcome space contain 2^10000 2^10000 possible outcomes! We can define abstractions on top of our probability space that makes dealing with large amounts of data or randomness easier. To do so, we define a random variable that converts each outcome to a real value. Definition : A random variable is a function X: \\Omega \\rightarrow \\mathbb{R}^d X: \\Omega \\rightarrow \\mathbb{R}^d . When flipping a coin, we can assign X = 1 X = 1 when the result is heads, or X = 0 X = 0 when the result is tails. Rather than say \"heads\" or \"tails\" our data is just zeros and ones. What if we flip the coin 10 times? Well, we collect 10 data points X_1, X_2, ..., X_{10} X_1, X_2, ..., X_{10} . The total number of heads Z Z would be Z = \\sum_{i=1}^{10} X_i Z = \\sum_{i=1}^{10} X_i , which is just an integer between 0 and 10. That's great, but what about probabilities? They simply carry over from the sample space: P(H) = P(X=1) = 0.5 P(H) = P(X=1) = 0.5 . P(HHHHHHHHHH) = P(Y=10) = (0.5)^{10} P(HHHHHHHHHH) = P(Y=10) = (0.5)^{10}","title":"Random Variables"},{"location":"machine%20learning/1data/#distributions","text":"The possible values of a random variable together with the probabilities that it takes on each value defines the distribution of the random variable. This allows us to reason about the characteristics of a random variable. Definition : The distribution of a random variable X X is the set of all values the random variable can take on x \\in \\mathcal{X} x \\in \\mathcal{X} , and their probabilities P(X = x) P(X = x) . Formally, (x, P(X=x)) \\forall x \\in \\mathcal{X} (x, P(X=x)) \\forall x \\in \\mathcal{X} . So far, this has worked great for coin-flipping, as everything has been an integer value! But what if we have a continuous set of outcomes, where the data we collect can take on any value in the interval [0,1] [0,1] . Let's try to assign probabilities. Let's say that P(0.025) = 0.0000001 P(0.025) = 0.0000001 , however there are an infinite number of possible outcomes, as there are infinitely many values between zero and one. If each outcome has non-zero probability, the total probability will sum to over 1! If we only assign non-zero probabilities to some outcomes, we reduce back to the discrete case. Thus, each outcome must have zero probability, yet they all sum to 1. To reconcile this disparity, we argue about continuous probability using random variables and distributions. Definition The distribution of a continuous random variable X X is defined by a probability density function f_X : X \\rightarrow \\mathbb{R} f_X : X \\rightarrow \\mathbb{R} such that: P(a \\leq X \\leq b) = \\int_a^b f_X(x) dx P(a \\leq X \\leq b) = \\int_a^b f_X(x) dx \\int_{-\\infty}^{\\infty} f_X(x) dx = 1 \\int_{-\\infty}^{\\infty} f_X(x) dx = 1 Intuitively, this defintion makes sense. If every value between 0 and 1 is equally likely, the probability P(X \\leq 0.5) P(X \\leq 0.5) should be 0.5. If we define f_X to be uniform and equal to 1 over the interval [0,1] [0,1] this happens to be the case. Note that the values of the density function f_X(x) f_X(x) can be larger than one, and even infinite! Below are some examples of distributions:","title":"Distributions"},{"location":"machine%20learning/1data/#expectation","text":"","title":"Expectation"},{"location":"machine%20learning/1data/#variance","text":"","title":"Variance"},{"location":"machine%20learning/1data/#data-in-ml","text":"In machine learning, we create a dataset containing samples from the real world.","title":"Data in ML"},{"location":"machine%20learning/2decisions/","text":"","title":"2decisions"},{"location":"machine%20learning/3models/","text":"","title":"3models"},{"location":"programming/python/","text":"0. About Python \u00b6 Python is an expansive language with tons of features that even veterans of the language can sometimes miss. This set of notes on python follow my investigations into the language and it's hidden features. These notes will not teach the python language, rather introduce some of it's advanced concepts that are not usually taught in intro courses. Topics here are presented in a semi-chronological order in order to make the information presented best understood. Topics Covered \u00b6 A checked box means that the topic is included, empty box implies that it's something to work on. C-like Data structures - named tuples, Enums, DataClass Comprehensions (list, dict, etc.) generators, iterators OOP: slots , hidden methods, abstract bass classes, locals()? GIL, threading, processes Map reduce, enumerate Regular and special data structures (collections, deque, queue) Lambdas Decorators pdb special operators if/else ternary operator closures! scoping: global local etc. Coroutines virtualenv args and kwargs (bring up how kwargs are instantiated once! Mutable!) getattr , setattr etc. building packages. web! sockets, http, etc.","title":"0. About Python"},{"location":"programming/python/#0-about-python","text":"Python is an expansive language with tons of features that even veterans of the language can sometimes miss. This set of notes on python follow my investigations into the language and it's hidden features. These notes will not teach the python language, rather introduce some of it's advanced concepts that are not usually taught in intro courses. Topics here are presented in a semi-chronological order in order to make the information presented best understood.","title":"0. About Python"},{"location":"programming/python/#topics-covered","text":"A checked box means that the topic is included, empty box implies that it's something to work on. C-like Data structures - named tuples, Enums, DataClass Comprehensions (list, dict, etc.) generators, iterators OOP: slots , hidden methods, abstract bass classes, locals()? GIL, threading, processes Map reduce, enumerate Regular and special data structures (collections, deque, queue) Lambdas Decorators pdb special operators if/else ternary operator closures! scoping: global local etc. Coroutines virtualenv args and kwargs (bring up how kwargs are instantiated once! Mutable!) getattr , setattr etc. building packages. web! sockets, http, etc.","title":"Topics Covered"},{"location":"programming/python/1objectmodel/","text":"1. The Object Model \u00b6 This section details the underpinnings of the Python language. It's possible to be a talented Python programmer without knowing any of the details presented in this section, but know them provides a fundamental understanding of the language. Essentially, everything in python is an object. Every variable you make is an object, every operation you execute is between objects. Seriously. int , float , functions, and anything else you can thing of: all objects that inherit from python's base object class, unsurprisingly named object . What does this mean? In python, primitive data types are in fact not very primitive at all, and are instead feature rich in comparison to their counterparts in lower level languages. Let's explore this a little bit by just looking at an integer. We'll create an int , then see what attributes it has by calling the dir function. When dir is called on an object, it recursively searches all the attributes of the argument and it's parents or base classes. >>> n = 1 >>> dir(n) ['__abs__', '__add__', '__and__', '__bool__', '__ceil__', '__class__', '__delattr__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floor__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getnewargs__', '__gt__', '__hash__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__le__', '__lshift__', '__lt__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__trunc__', '__xor__', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'numerator', 'real', 'to_bytes'] Wow! There's a lot more to an integer than just a value. In lower level languages, like C, C++, or Java, primitive types refer to sections of memory, designated to contain a specifc value that can be directly manipulted in assembly code or even transistor level logic in CPUs. Python sits at a much higher abstraction level. Though python is slower than the aforementioned languages, the programmer doesn't have to deal with problems like overflow, underflow, or invalid type casting as all of this is abstracted away through objects. Some the attributes listed through dir(int) are class specific to int , and some are inherited from object . Let's see what attributes object by calling dir on the static type itself. >>> dir(object) ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__'] By the end of this note, you should understand what most of the different attributes listed above do. But, with so many different types of objects we have to have some way of discerning between different types. NotImplemented Python has one special object run globally called NotImplemented . It can be used when object's don't implement some of the default binary function attributes given to them by the object class. type(NotImplemented) = <class 'NotImplementedType'> . Typing \u00b6 Python provides a few built-in functions to help distinguish between objects of different types. type(arg) : the type function returns a Type Object representing the type or class of its argument. For example: >>> type(int) <class 'type'> >>> type(type(int)) <class 'type'> Though this function returns the type of an object, there are built-in functions more specifically designed for comparing the types of two differnet objects. The first is the isinstance(object, classInfo) function. It takes in an object (can be static type or instance) as the first argument, and a tuple of types as the second parameter. For example: >>> n = 1.0 >>> isinstance(n, int) False >>> isinstance(n, (int, float)) True issubclass(class, classInfo) is used less, but is useful for determining if a given class is a sub class of another. For example, issubclass(int, object) gives True . None \u00b6 The None object represents, well, nothing. None is globally unique and is the only possible value of objects of type None . How objects store values \u00b6 __dict__ \u00b6 In Python, objects store all of their attributes in dictionary or dictionary like objects. The vars function lists all of the attributes in an objects __dict__ . The result of a vars call differs if the argument is an object type or an object instance. When called on an object type, for example vars(int) , the output is very similar to that of dir (except it won't look at base classes), but it returns a protected dictionary called mappingproxy that contains attributes and their values pertinate to the static or class level attributes of a type. Calling vars on an instance returns the attributes pertinate to the instance. Here's an example to demonstrate: >>> class Test(object): ... static_val = 0 ... def test(self): ... pass ... >>> t = Test() >>> t.inst_val = 1 >>> vars(Test) mappingproxy({'__module__': '__main__', 'static_val': 0, 'test': <function Test.test at 0x7f072c48d730>, '__dict__': <attribute '__dict__' of 'Test' objects>, '__weakref__': <attribute '__weakref__' of 'Test' objects>, '__doc__': None}) >>> vars(t) {'inst_val': 1} Note calling vars is essentially equivalent to accessing the __dict__ attribute of an object type or an object instance). It's worth noting that some object instances, like those of type int do not actually have a __dict__ attribute. This really only seems to apply to primitive-like or built-in types. In fact, because Python objects store their values using the __dict__ attribute, we can actually create very basic objects using the type function. By passing more parameters to the type function, it actually creates a new type object. The following are two identical ways of creating the same object. >>> class X: ... a = 1 ... >>> X = type('X', (object,), dict(a=1)) Getters and Setters. \u00b6 Python additionally has a set of built in set of methods for getting, setting, and deleting attributes. The object base class has the following getter and setter methods which are wrapped by built-in python functions. Object Method Built-in Function Description object.__getattribute__('name') getattr(object, 'name') Gets attribute object.__setattr__('name', value) setattr(object, 'name', value) Sets attribute to value object.__delattr('name') delattr(object, 'name') Deletes attribute N/A hasattr(object, 'name') Checks if an object has an attribute. Mutable vs Immutable Objects \u00b6 In Python, objects fit into one of two categories: mutable, or immutable. Immutable objects have to be copied in order to change, whereas mutable objects do not. Upon instantiation, every object in Python is assigned a unique ID that often corresponds to it's location in memory and can be accessed via the id(obj) method. Immutable objects derive their concepet of uniqueness from the values they contian, rather than their instantiation in memory. This means that if we change the value of an immutable object held by a variable, we are actually creating a new object and changing the variable to point at the new object. Here's an example: >>> a = 0; id(a) 10968768 >>> b = 1; id(b) 10968800 >>> a +=1; id(a) 10968800 >>> c = \"hi\"; id(c); d = \"hi\"; id(d) 140191817812880 140191817812880 Notice how on each assignment, the ID of each variable completely changes as it points to a new object. Primitive like types are immutable because of the speed benefits an immutable object offers. As primitive objects are not large or complex, we do not incur a large cost when copying or re-instantiating them upon changing a value. Additionally, passing immutable types to functions is always safe , as we can't actually modify the underlying object is a variable is pointing to. Note ID's will not always be the same for the \"same\" immutable object. For example, if we execute a = \"hi\"; b = \"h\"; b += \"i\" , id(a) and id(b) will not be the same. This is because we don't recheck memory to determine if the same string has already been used and instead just allocate new space for the new string. The following are Immutable in Python : int, float, complex, string, tuple, frozen set, bytes Every other object is mutable. Mutable objects are not copied and are instead modified in place. This means that operations on mutable types can be unsafe when passed to functions as the function is able to change the underlying object. For example, >>> a = [1]; id(a) 140191817820232 >>> b = [1, 2]; id(b) 140191817818952 >>> a.append(2); id(a) 140191817820232 is vs == \u00b6 The python is operator simply compares the id of the two objects, or does an integer comparison id(a) == id(b) . The == operator on the other hand, calls the special __eq__ comparison operator defined between objects. Unless overrided, this defaults to simply doing the same id comparison as is . Thus, unless the __eq__ method is specified, == comparisons between custom objects in Python won't behave as expected. A Tricky Example \u00b6 In Python, tuples are a basic immutable data type that represent a fixed length of fixed values. Let's look at a complicated example using tuples to drive mutability vs immutability home. >>> a, b = (0, [1, 2]) , (0, [1, 2]) >>> a == b; id(a) == id(b) True False What happened here? Even though the tuples look identical, they are actually different! This is because the list created for a and the list created for b are actually distinct, different objects as they are mutable. When we check a == b , the __eq__ function is called recursively on all the members of the two tuples, thus showing they are equal, but the IDs of the two tuples are different because they were created with different list objects. If we instantiated them with the same list, they would have the same id. l = [1, 2]; id( (0, l) ) == id( (0, l) ) yeilds True. Type Casting In Python \u00b6 One consequence of all of the object model is that Python really does not have \"casting\" in the traditional sense. When you convert a int to a float by running something along the lines of float(n) , a specific verison of the float constructor is actually called that takes in an argument. A new object is then created based off of the parameter. Thus, when you type cast, you are really just initializing a new object. Special Object Functions and Operators \u00b6 In order to enable consistent usage across all of the different objects in Python, they all utilize the same special methods denoted with two underscores on either side __func__ . Overriding these objects in your own implementations can lead to neat and concise code for complex functions. They can be overriden by defining the __func__(self, [args]) function within an object. These functions are often refered to as \"magic\" functions. Ommited from this list are the getter and setter attributes discussed previously in this section and other attributes that are more specific to different types of data structures. Attribute Built-In Accesor Descripton __new__ N/A Called when creating a new instance of an object __init__ N/A Called when instantiating a new instance of an object, after __new__ __class__ type(obj) Returns the type of a given object. __str__ str(obj) Converts object to a string. This is called when printed. __repr__ repr(obj) Returns a representation of the object used in the python shell. __doc__ `help(obj) Gives documentation for the given type. __hash__ hash(obj) Custom hash function for the object. __get__ N/A Invoked every time an object is accessed. Used by function objects to make them callable. Similar definition for __set__ __eq__ == Provides comparison binary operator. Other comaprison operators are __lt__ , __le__ , __ne__ , __ge__ , __gt__ __add__ add(a, b), + Overrides math functionality. Others are __sub__ , __mul__ , __abs__ , __floordiv__ , __truediv__ , __pow__ , etc. __getitem__ object[ind] Returns value of an object at a certain index __and__ and Returns logical and. Other logical operators are __or__ , __not__ , __xor__ , __lshift__ , etc. __contains__ val in obj Checks to see if an object contains a value using in keyword. __next__ next(obj) yeilds next value of an object __yield__ iter(obj), for _ in obj returns an iterator over the values of the object You can find more operator attributes at this link: https://docs.python.org/3/library/operator.html Sources and Further Reading \u00b6 https://docs.python.org/3.7/reference/datamodel.html https://docs.python.org/3/library/functions.html https://docs.python.org/3/library/constants.html https://docs.python.org/3/library/stdtypes.html","title":"1. The Object Model"},{"location":"programming/python/1objectmodel/#1-the-object-model","text":"This section details the underpinnings of the Python language. It's possible to be a talented Python programmer without knowing any of the details presented in this section, but know them provides a fundamental understanding of the language. Essentially, everything in python is an object. Every variable you make is an object, every operation you execute is between objects. Seriously. int , float , functions, and anything else you can thing of: all objects that inherit from python's base object class, unsurprisingly named object . What does this mean? In python, primitive data types are in fact not very primitive at all, and are instead feature rich in comparison to their counterparts in lower level languages. Let's explore this a little bit by just looking at an integer. We'll create an int , then see what attributes it has by calling the dir function. When dir is called on an object, it recursively searches all the attributes of the argument and it's parents or base classes. >>> n = 1 >>> dir(n) ['__abs__', '__add__', '__and__', '__bool__', '__ceil__', '__class__', '__delattr__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floor__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getnewargs__', '__gt__', '__hash__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__le__', '__lshift__', '__lt__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__trunc__', '__xor__', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'numerator', 'real', 'to_bytes'] Wow! There's a lot more to an integer than just a value. In lower level languages, like C, C++, or Java, primitive types refer to sections of memory, designated to contain a specifc value that can be directly manipulted in assembly code or even transistor level logic in CPUs. Python sits at a much higher abstraction level. Though python is slower than the aforementioned languages, the programmer doesn't have to deal with problems like overflow, underflow, or invalid type casting as all of this is abstracted away through objects. Some the attributes listed through dir(int) are class specific to int , and some are inherited from object . Let's see what attributes object by calling dir on the static type itself. >>> dir(object) ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__'] By the end of this note, you should understand what most of the different attributes listed above do. But, with so many different types of objects we have to have some way of discerning between different types. NotImplemented Python has one special object run globally called NotImplemented . It can be used when object's don't implement some of the default binary function attributes given to them by the object class. type(NotImplemented) = <class 'NotImplementedType'> .","title":"1. The Object Model"},{"location":"programming/python/1objectmodel/#typing","text":"Python provides a few built-in functions to help distinguish between objects of different types. type(arg) : the type function returns a Type Object representing the type or class of its argument. For example: >>> type(int) <class 'type'> >>> type(type(int)) <class 'type'> Though this function returns the type of an object, there are built-in functions more specifically designed for comparing the types of two differnet objects. The first is the isinstance(object, classInfo) function. It takes in an object (can be static type or instance) as the first argument, and a tuple of types as the second parameter. For example: >>> n = 1.0 >>> isinstance(n, int) False >>> isinstance(n, (int, float)) True issubclass(class, classInfo) is used less, but is useful for determining if a given class is a sub class of another. For example, issubclass(int, object) gives True .","title":"Typing"},{"location":"programming/python/1objectmodel/#none","text":"The None object represents, well, nothing. None is globally unique and is the only possible value of objects of type None .","title":"None"},{"location":"programming/python/1objectmodel/#how-objects-store-values","text":"","title":"How objects store values"},{"location":"programming/python/1objectmodel/#__dict__","text":"In Python, objects store all of their attributes in dictionary or dictionary like objects. The vars function lists all of the attributes in an objects __dict__ . The result of a vars call differs if the argument is an object type or an object instance. When called on an object type, for example vars(int) , the output is very similar to that of dir (except it won't look at base classes), but it returns a protected dictionary called mappingproxy that contains attributes and their values pertinate to the static or class level attributes of a type. Calling vars on an instance returns the attributes pertinate to the instance. Here's an example to demonstrate: >>> class Test(object): ... static_val = 0 ... def test(self): ... pass ... >>> t = Test() >>> t.inst_val = 1 >>> vars(Test) mappingproxy({'__module__': '__main__', 'static_val': 0, 'test': <function Test.test at 0x7f072c48d730>, '__dict__': <attribute '__dict__' of 'Test' objects>, '__weakref__': <attribute '__weakref__' of 'Test' objects>, '__doc__': None}) >>> vars(t) {'inst_val': 1} Note calling vars is essentially equivalent to accessing the __dict__ attribute of an object type or an object instance). It's worth noting that some object instances, like those of type int do not actually have a __dict__ attribute. This really only seems to apply to primitive-like or built-in types. In fact, because Python objects store their values using the __dict__ attribute, we can actually create very basic objects using the type function. By passing more parameters to the type function, it actually creates a new type object. The following are two identical ways of creating the same object. >>> class X: ... a = 1 ... >>> X = type('X', (object,), dict(a=1))","title":"__dict__"},{"location":"programming/python/1objectmodel/#getters-and-setters","text":"Python additionally has a set of built in set of methods for getting, setting, and deleting attributes. The object base class has the following getter and setter methods which are wrapped by built-in python functions. Object Method Built-in Function Description object.__getattribute__('name') getattr(object, 'name') Gets attribute object.__setattr__('name', value) setattr(object, 'name', value) Sets attribute to value object.__delattr('name') delattr(object, 'name') Deletes attribute N/A hasattr(object, 'name') Checks if an object has an attribute.","title":"Getters and Setters."},{"location":"programming/python/1objectmodel/#mutable-vs-immutable-objects","text":"In Python, objects fit into one of two categories: mutable, or immutable. Immutable objects have to be copied in order to change, whereas mutable objects do not. Upon instantiation, every object in Python is assigned a unique ID that often corresponds to it's location in memory and can be accessed via the id(obj) method. Immutable objects derive their concepet of uniqueness from the values they contian, rather than their instantiation in memory. This means that if we change the value of an immutable object held by a variable, we are actually creating a new object and changing the variable to point at the new object. Here's an example: >>> a = 0; id(a) 10968768 >>> b = 1; id(b) 10968800 >>> a +=1; id(a) 10968800 >>> c = \"hi\"; id(c); d = \"hi\"; id(d) 140191817812880 140191817812880 Notice how on each assignment, the ID of each variable completely changes as it points to a new object. Primitive like types are immutable because of the speed benefits an immutable object offers. As primitive objects are not large or complex, we do not incur a large cost when copying or re-instantiating them upon changing a value. Additionally, passing immutable types to functions is always safe , as we can't actually modify the underlying object is a variable is pointing to. Note ID's will not always be the same for the \"same\" immutable object. For example, if we execute a = \"hi\"; b = \"h\"; b += \"i\" , id(a) and id(b) will not be the same. This is because we don't recheck memory to determine if the same string has already been used and instead just allocate new space for the new string. The following are Immutable in Python : int, float, complex, string, tuple, frozen set, bytes Every other object is mutable. Mutable objects are not copied and are instead modified in place. This means that operations on mutable types can be unsafe when passed to functions as the function is able to change the underlying object. For example, >>> a = [1]; id(a) 140191817820232 >>> b = [1, 2]; id(b) 140191817818952 >>> a.append(2); id(a) 140191817820232","title":"Mutable vs Immutable Objects"},{"location":"programming/python/1objectmodel/#is-vs","text":"The python is operator simply compares the id of the two objects, or does an integer comparison id(a) == id(b) . The == operator on the other hand, calls the special __eq__ comparison operator defined between objects. Unless overrided, this defaults to simply doing the same id comparison as is . Thus, unless the __eq__ method is specified, == comparisons between custom objects in Python won't behave as expected.","title":"is vs =="},{"location":"programming/python/1objectmodel/#a-tricky-example","text":"In Python, tuples are a basic immutable data type that represent a fixed length of fixed values. Let's look at a complicated example using tuples to drive mutability vs immutability home. >>> a, b = (0, [1, 2]) , (0, [1, 2]) >>> a == b; id(a) == id(b) True False What happened here? Even though the tuples look identical, they are actually different! This is because the list created for a and the list created for b are actually distinct, different objects as they are mutable. When we check a == b , the __eq__ function is called recursively on all the members of the two tuples, thus showing they are equal, but the IDs of the two tuples are different because they were created with different list objects. If we instantiated them with the same list, they would have the same id. l = [1, 2]; id( (0, l) ) == id( (0, l) ) yeilds True.","title":"A Tricky Example"},{"location":"programming/python/1objectmodel/#type-casting-in-python","text":"One consequence of all of the object model is that Python really does not have \"casting\" in the traditional sense. When you convert a int to a float by running something along the lines of float(n) , a specific verison of the float constructor is actually called that takes in an argument. A new object is then created based off of the parameter. Thus, when you type cast, you are really just initializing a new object.","title":"Type Casting In Python"},{"location":"programming/python/1objectmodel/#special-object-functions-and-operators","text":"In order to enable consistent usage across all of the different objects in Python, they all utilize the same special methods denoted with two underscores on either side __func__ . Overriding these objects in your own implementations can lead to neat and concise code for complex functions. They can be overriden by defining the __func__(self, [args]) function within an object. These functions are often refered to as \"magic\" functions. Ommited from this list are the getter and setter attributes discussed previously in this section and other attributes that are more specific to different types of data structures. Attribute Built-In Accesor Descripton __new__ N/A Called when creating a new instance of an object __init__ N/A Called when instantiating a new instance of an object, after __new__ __class__ type(obj) Returns the type of a given object. __str__ str(obj) Converts object to a string. This is called when printed. __repr__ repr(obj) Returns a representation of the object used in the python shell. __doc__ `help(obj) Gives documentation for the given type. __hash__ hash(obj) Custom hash function for the object. __get__ N/A Invoked every time an object is accessed. Used by function objects to make them callable. Similar definition for __set__ __eq__ == Provides comparison binary operator. Other comaprison operators are __lt__ , __le__ , __ne__ , __ge__ , __gt__ __add__ add(a, b), + Overrides math functionality. Others are __sub__ , __mul__ , __abs__ , __floordiv__ , __truediv__ , __pow__ , etc. __getitem__ object[ind] Returns value of an object at a certain index __and__ and Returns logical and. Other logical operators are __or__ , __not__ , __xor__ , __lshift__ , etc. __contains__ val in obj Checks to see if an object contains a value using in keyword. __next__ next(obj) yeilds next value of an object __yield__ iter(obj), for _ in obj returns an iterator over the values of the object You can find more operator attributes at this link: https://docs.python.org/3/library/operator.html","title":"Special Object Functions and Operators"},{"location":"programming/python/1objectmodel/#sources-and-further-reading","text":"https://docs.python.org/3.7/reference/datamodel.html https://docs.python.org/3/library/functions.html https://docs.python.org/3/library/constants.html https://docs.python.org/3/library/stdtypes.html","title":"Sources and Further Reading"},{"location":"programming/python/2syntax/","text":"2. Syntax \u00b6 This section covers some finer details of python's syntax, along with a few extra tid-bits. Scoping \u00b6 In python, scopes are defined by dict like namespaces, similar to those found in objects. Within objects (and thus within functions), different namespaces are applied than the global python namespace. When python looks up the value attributed to a variable name, it first looks up the name in it's immediate scope by checking the namespace of the object the function is in. If it doesn't find the given variable there, it proceeds down the call stack searching for it, until it finds the variable or reaches the global scope and can't find it. x = \"global\" def fn1(): x = \"local\" print(x) def fn2(): print(x) print(x) # global fn1() # local fn2() # global You can access the local namespace by calling the locals() function, or the global namespace by calling the globals() function, both of which return key attribute dictionaries. nonlocal \u00b6 The nonlocal keyword in python can be used in nested functions to make a given variable refer to one that is used in a different scope. This essentially binds the variable in local scope to the variable in the next higher level scope where it is defined. def outer(): x = \"outer\" def inner(): nonlocal x x = \"inner\" print(\"From Inner:\", x) inner() print(\"From Outer:\", x) outer() This code yields the following result: From Inner: inner From Outer: inner This is because the variable x is set to refer to the namespace of outer with the nonlocal keyword. Thus, x gets set to \"inner\" in the namespace of outer. If nonlocal was not present, we would instead get the expected result of inner from inner and outer from outer. global \u00b6 While nonlocal can refer to external scopes, the keyword global can be used to make variables refer to their versions in the global namespace. The global key word makes a given variable refer to the global scope. Be careful though the global and nonlocal descriptors only take effect in a given scope. The following example demonstrates this. x = \"global\" def outer(): x = \"outer\" def inner(): global x x = \"inner\" print(\"From Inner:\", x) inner() print(\"From Outer:\", x) outer() print(\"From Global:\", x) The result of running this is: From Inner: inner From Outer: outer From Global: inner Note that in the scope of outer the variable is unchanged. This is because the binding of global only takes effect within the scope it is used. As expected, in inner , x will refer to the global variable and change it to \"inner\". Variable Naming \u00b6 Python has no strict for scoping variables as private or public. Instead, naming conventions are used in order to indicate a variables type of access. Single underscores as prefixes, like _variable are used to indicate private attributes of an object. In messy situations with inheritance, double underscores, like __variable can be used. At runtime, these varaible names have the class type prepended along with underscores, to form a name like __classname__variable . This can be used to automatically prevent name conflicts between parent and sub classes. Double underscores on either side of a variable name, like __variable__ refer to attributes that are directly used by the python interpreter. Changing or overriding these functions is not garunteed to be safe in general. Ternary Operator \u00b6 Most people don't know about it, but python actually has a ternary operator. It is of the following form: true_result if condition else false_result The same effect can be achieved with tuples, though the first method is preferable as it is more readable. (true_result, false_result)[condition] This works because True casts to the integer value 1 while False casts to the integer value 0. The Python Debugger \u00b6 pdb is amazing. Not many people use it. It basically allows you to insert yourself in the middle of python's repl loop and step through any part of execution and manipulate variables at will. I've found it to be super useful. You can use it at any point by just importing pdb , then running pdb.set_trace() . A lot of Python programmers debug with print statements, and I find pdb to be much faster sometimes. Using pdb is straight forward and you can find it's documentation here . for and else \u00b6 One relatively unknown part of basic python control flow is the for and else combination. You can include an else clause at the end of for loops in python that will execute if no break is called. When searching through iteratbles, this can act as an ending \"catch-all\" if no matching item is found. THe official Python documentation has this example that finds all the prime numbers between 2 and 9 inclusive. for n in range(2, 10): for x in range(2, n): if n % x == 0: print( n, 'equals', x, '*', n/x) break else: # loop fell through without finding a factor print(n, 'is a prime number') If a number n doesn't have any factors, we will never hit the break and thus the else clause will be invoked. del \u00b6 Python handles garbage collection automatically, so you don't need to give memory usage or space allocation much thought. However, python still provides teh del keyword, which can be used to delete objects and free the space in memory they consumed. Just specify del obj . One feature of note is that the del operator works on indices. For example, del lst[3] will delete the third item of the list lst .","title":"2. Syntax"},{"location":"programming/python/2syntax/#2-syntax","text":"This section covers some finer details of python's syntax, along with a few extra tid-bits.","title":"2. Syntax"},{"location":"programming/python/2syntax/#scoping","text":"In python, scopes are defined by dict like namespaces, similar to those found in objects. Within objects (and thus within functions), different namespaces are applied than the global python namespace. When python looks up the value attributed to a variable name, it first looks up the name in it's immediate scope by checking the namespace of the object the function is in. If it doesn't find the given variable there, it proceeds down the call stack searching for it, until it finds the variable or reaches the global scope and can't find it. x = \"global\" def fn1(): x = \"local\" print(x) def fn2(): print(x) print(x) # global fn1() # local fn2() # global You can access the local namespace by calling the locals() function, or the global namespace by calling the globals() function, both of which return key attribute dictionaries.","title":"Scoping"},{"location":"programming/python/2syntax/#nonlocal","text":"The nonlocal keyword in python can be used in nested functions to make a given variable refer to one that is used in a different scope. This essentially binds the variable in local scope to the variable in the next higher level scope where it is defined. def outer(): x = \"outer\" def inner(): nonlocal x x = \"inner\" print(\"From Inner:\", x) inner() print(\"From Outer:\", x) outer() This code yields the following result: From Inner: inner From Outer: inner This is because the variable x is set to refer to the namespace of outer with the nonlocal keyword. Thus, x gets set to \"inner\" in the namespace of outer. If nonlocal was not present, we would instead get the expected result of inner from inner and outer from outer.","title":"nonlocal"},{"location":"programming/python/2syntax/#global","text":"While nonlocal can refer to external scopes, the keyword global can be used to make variables refer to their versions in the global namespace. The global key word makes a given variable refer to the global scope. Be careful though the global and nonlocal descriptors only take effect in a given scope. The following example demonstrates this. x = \"global\" def outer(): x = \"outer\" def inner(): global x x = \"inner\" print(\"From Inner:\", x) inner() print(\"From Outer:\", x) outer() print(\"From Global:\", x) The result of running this is: From Inner: inner From Outer: outer From Global: inner Note that in the scope of outer the variable is unchanged. This is because the binding of global only takes effect within the scope it is used. As expected, in inner , x will refer to the global variable and change it to \"inner\".","title":"global"},{"location":"programming/python/2syntax/#variable-naming","text":"Python has no strict for scoping variables as private or public. Instead, naming conventions are used in order to indicate a variables type of access. Single underscores as prefixes, like _variable are used to indicate private attributes of an object. In messy situations with inheritance, double underscores, like __variable can be used. At runtime, these varaible names have the class type prepended along with underscores, to form a name like __classname__variable . This can be used to automatically prevent name conflicts between parent and sub classes. Double underscores on either side of a variable name, like __variable__ refer to attributes that are directly used by the python interpreter. Changing or overriding these functions is not garunteed to be safe in general.","title":"Variable Naming"},{"location":"programming/python/2syntax/#ternary-operator","text":"Most people don't know about it, but python actually has a ternary operator. It is of the following form: true_result if condition else false_result The same effect can be achieved with tuples, though the first method is preferable as it is more readable. (true_result, false_result)[condition] This works because True casts to the integer value 1 while False casts to the integer value 0.","title":"Ternary Operator"},{"location":"programming/python/2syntax/#the-python-debugger","text":"pdb is amazing. Not many people use it. It basically allows you to insert yourself in the middle of python's repl loop and step through any part of execution and manipulate variables at will. I've found it to be super useful. You can use it at any point by just importing pdb , then running pdb.set_trace() . A lot of Python programmers debug with print statements, and I find pdb to be much faster sometimes. Using pdb is straight forward and you can find it's documentation here .","title":"The Python Debugger"},{"location":"programming/python/2syntax/#for-and-else","text":"One relatively unknown part of basic python control flow is the for and else combination. You can include an else clause at the end of for loops in python that will execute if no break is called. When searching through iteratbles, this can act as an ending \"catch-all\" if no matching item is found. THe official Python documentation has this example that finds all the prime numbers between 2 and 9 inclusive. for n in range(2, 10): for x in range(2, n): if n % x == 0: print( n, 'equals', x, '*', n/x) break else: # loop fell through without finding a factor print(n, 'is a prime number') If a number n doesn't have any factors, we will never hit the break and thus the else clause will be invoked.","title":"for and else"},{"location":"programming/python/2syntax/#del","text":"Python handles garbage collection automatically, so you don't need to give memory usage or space allocation much thought. However, python still provides teh del keyword, which can be used to delete objects and free the space in memory they consumed. Just specify del obj . One feature of note is that the del operator works on indices. For example, del lst[3] will delete the third item of the list lst .","title":"del"},{"location":"programming/python/3functions/","text":"3. Functions \u00b6 In python, all functions are actually just objects. Thus as a result, they can be passed as parameters just as any other type, stor__ed in other objects/data structures, or assinged to variables. This makes using functions in Python extremely versetile. Functions are made callable as they define the special __call__ method. Any object that implements this method will become callable itself. *args and **kwargs \u00b6 The * operator in python is often overlooked, but can be extremely useful. It unpacks an iterable and essentially replaces it with a comma seperated list of its content inline. This can be seen in the following example. >>> int.__eq__(*[1, 2]) False int.__eq__ is the implementation of the binary equality function between integer objects, and thus accepts two integers. The * unpacks the arguments so the line is equivalent to int.__eq__(1, 2) . *args allows you to pass a variable number of arguments to a python function. For example, let's write an add function that accepts any number of objects to add. >>> def add(*args): ... total = 0 ... for arg in args: ... total += arg ... return total >>> add(1, 4, -1, 7) 11 **kwargs unpacks keyword arguments. It is given in the form of a dictionary of string keys mapping from the name of the keyword argument to it's value. Here's an example to demonstrate this. >>> def print_kwargs(**kwargs): ... for arg_name, arg_val in kwargs.items(): ... print(arg_name, arg_val) ... >>> print_kwargs(a=10, b=2) a 10 b 2 If you are using *args and **kwargs , required parameters must be specified first followed by args then kwargs : def fn(req_arg1, req_arg2, *args, **kwargs) You can use unpacking to call any function as well. Let's say we have a function with the following header: def fn(a1, a2, kw1=0, kw2=True, kw3=[]) . We could define the variables args = (\"a1\", \"a2\") and kwargs = {\"kw1\" : 0} , then call fn(*args, **kwargs) . Return \u00b6 By default, Python functions that don't explicitly return a value will return the None object. Additionally, when returning multiple values, they are implicitly wrapped in a tuple that you can use as a tuple, or implicitly unpack. >>> def fn(): return 0, 1 ... >>> fn() (0, 1) >>> a, b = fn() >>> print(a, b) 0 1 Typing \u00b6 Python 3.5 adding the typing module that allows for type hinting within functions. You can read the full documentation here . The typing module will perform checks on function arguments are return types to verify that they are behaving as desired. High quality code can leverage typing to improve readability and correctness. Within function signatures, a colon : following an argument indicuates its expected type and a an arrow -> after the parenthetical indicates the expected return type. def append_and_return(items: list, item : int) -> list: items.append(item) return items def get(map: dict, key: str) -> int: return map[key] Type Aliases \u00b6 The typing module includes support for aliases that can be leveraged for more complex type verification. Aliases for all of the common python data types already exist inclduing List , Dict , Tuple , and Set . Objects from the typing module have a bracket operator that allows you to indicate what type of items an object might hold. from typing import List, Dict, Tuple, Set def dot(vec_1: List[float], vec_2: List[float]) -> float: # implementation We can also rewrite the same signature using a type alias. We create a new typing object that further defines the signature. Vector = List[float] def dot(vec_1: Vector, vec_2: Vector) -> float: # implementation Both of the above examples are identical. Here's a more complex example taken from the Python documentation linked earlier. ConnectionOptions = Dict[str, str] Address = Tuple[str, int] Server = Tuple[Address, ConnectionOptions] def broadcast_message(message: str, servers: Sequence[Server]) -> None: Decorators \u00b6 Function Caching \u00b6 Lambdas \u00b6","title":"3. Functions"},{"location":"programming/python/3functions/#3-functions","text":"In python, all functions are actually just objects. Thus as a result, they can be passed as parameters just as any other type, stor__ed in other objects/data structures, or assinged to variables. This makes using functions in Python extremely versetile. Functions are made callable as they define the special __call__ method. Any object that implements this method will become callable itself.","title":"3. Functions"},{"location":"programming/python/3functions/#args-and-kwargs","text":"The * operator in python is often overlooked, but can be extremely useful. It unpacks an iterable and essentially replaces it with a comma seperated list of its content inline. This can be seen in the following example. >>> int.__eq__(*[1, 2]) False int.__eq__ is the implementation of the binary equality function between integer objects, and thus accepts two integers. The * unpacks the arguments so the line is equivalent to int.__eq__(1, 2) . *args allows you to pass a variable number of arguments to a python function. For example, let's write an add function that accepts any number of objects to add. >>> def add(*args): ... total = 0 ... for arg in args: ... total += arg ... return total >>> add(1, 4, -1, 7) 11 **kwargs unpacks keyword arguments. It is given in the form of a dictionary of string keys mapping from the name of the keyword argument to it's value. Here's an example to demonstrate this. >>> def print_kwargs(**kwargs): ... for arg_name, arg_val in kwargs.items(): ... print(arg_name, arg_val) ... >>> print_kwargs(a=10, b=2) a 10 b 2 If you are using *args and **kwargs , required parameters must be specified first followed by args then kwargs : def fn(req_arg1, req_arg2, *args, **kwargs) You can use unpacking to call any function as well. Let's say we have a function with the following header: def fn(a1, a2, kw1=0, kw2=True, kw3=[]) . We could define the variables args = (\"a1\", \"a2\") and kwargs = {\"kw1\" : 0} , then call fn(*args, **kwargs) .","title":"*args and **kwargs"},{"location":"programming/python/3functions/#return","text":"By default, Python functions that don't explicitly return a value will return the None object. Additionally, when returning multiple values, they are implicitly wrapped in a tuple that you can use as a tuple, or implicitly unpack. >>> def fn(): return 0, 1 ... >>> fn() (0, 1) >>> a, b = fn() >>> print(a, b) 0 1","title":"Return"},{"location":"programming/python/3functions/#typing","text":"Python 3.5 adding the typing module that allows for type hinting within functions. You can read the full documentation here . The typing module will perform checks on function arguments are return types to verify that they are behaving as desired. High quality code can leverage typing to improve readability and correctness. Within function signatures, a colon : following an argument indicuates its expected type and a an arrow -> after the parenthetical indicates the expected return type. def append_and_return(items: list, item : int) -> list: items.append(item) return items def get(map: dict, key: str) -> int: return map[key]","title":"Typing"},{"location":"programming/python/3functions/#type-aliases","text":"The typing module includes support for aliases that can be leveraged for more complex type verification. Aliases for all of the common python data types already exist inclduing List , Dict , Tuple , and Set . Objects from the typing module have a bracket operator that allows you to indicate what type of items an object might hold. from typing import List, Dict, Tuple, Set def dot(vec_1: List[float], vec_2: List[float]) -> float: # implementation We can also rewrite the same signature using a type alias. We create a new typing object that further defines the signature. Vector = List[float] def dot(vec_1: Vector, vec_2: Vector) -> float: # implementation Both of the above examples are identical. Here's a more complex example taken from the Python documentation linked earlier. ConnectionOptions = Dict[str, str] Address = Tuple[str, int] Server = Tuple[Address, ConnectionOptions] def broadcast_message(message: str, servers: Sequence[Server]) -> None:","title":"Type Aliases"},{"location":"programming/python/3functions/#decorators","text":"","title":"Decorators"},{"location":"programming/python/3functions/#function-caching","text":"","title":"Function Caching"},{"location":"programming/python/3functions/#lambdas","text":"","title":"Lambdas"},{"location":"programming/python/4datastructures/","text":"3. Data Structures \u00b6 Named Tuples","title":"3. Data Structures"},{"location":"programming/python/4datastructures/#3-data-structures","text":"Named Tuples","title":"3. Data Structures"},{"location":"programming/python/5oop/","text":"5. Object Oriented Programming \u00b6 https://docs.python.org/3/howto/descriptor.html","title":"5. Object Oriented Programming"},{"location":"programming/python/5oop/#5-object-oriented-programming","text":"https://docs.python.org/3/howto/descriptor.html","title":"5. Object Oriented Programming"},{"location":"teaching/cs189/","text":"CS 189 Sp 20 \u00b6 Resources for Joey Hejna's Spring 2020 CS 189 Discussion section on Tuesdays 2:00-3:00 PM in Barrows 185. Feedback \u00b6 Please submit anonymous feedback via this form . Section Notes \u00b6 Copies of all of my work from section can be found at this google drive folder","title":"CS 189 Sp 20"},{"location":"teaching/cs189/#cs-189-sp-20","text":"Resources for Joey Hejna's Spring 2020 CS 189 Discussion section on Tuesdays 2:00-3:00 PM in Barrows 185.","title":"CS 189 Sp 20"},{"location":"teaching/cs189/#feedback","text":"Please submit anonymous feedback via this form .","title":"Feedback"},{"location":"teaching/cs189/#section-notes","text":"Copies of all of my work from section can be found at this google drive folder","title":"Section Notes"},{"location":"teaching/cs70/","text":"CS 70 Fa 20 \u00b6 Resources for Joey Hejna's Fall 2019 CS 70 Discussion section on Tuesdays and Thursdays 2:00-3:00 PM in Wheeler 30. Questions \u00b6 This semester, our Tuesday discussion sections will be used for content review and questions. You can submit questions or topics using this form Feedback \u00b6 Please submit anonymous feedback via this form . Section Notes \u00b6 Copies of all of my work from section can be found at this google drive folder","title":"CS 70 Fa 20"},{"location":"teaching/cs70/#cs-70-fa-20","text":"Resources for Joey Hejna's Fall 2019 CS 70 Discussion section on Tuesdays and Thursdays 2:00-3:00 PM in Wheeler 30.","title":"CS 70 Fa 20"},{"location":"teaching/cs70/#questions","text":"This semester, our Tuesday discussion sections will be used for content review and questions. You can submit questions or topics using this form","title":"Questions"},{"location":"teaching/cs70/#feedback","text":"Please submit anonymous feedback via this form .","title":"Feedback"},{"location":"teaching/cs70/#section-notes","text":"Copies of all of my work from section can be found at this google drive folder","title":"Section Notes"}]}